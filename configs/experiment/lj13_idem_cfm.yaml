# @package _global_

# to execute this experiment run:
# python train.py experiment=example

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

defaults:
  - override /energy: lj13
  - override /model/net: egnn
  - override /model/noise_schedule: geometric

tags: ["LJ13", "CFM", "NLL_eval"]

seed: 12345

logger:
  wandb:
    tags: ${tags}
    group: "lj13"

# You need to fill energy.data_path_train at the command line with samples generated
# by running dem/eval.py on a checkpoint
energy:
  data_path_train: null

data:
  n_val_batches_per_epoch: 4

trainer:
  check_val_every_n_epoch: 1
  max_epochs: 2000

model:
  debug_use_train_data: true
  use_otcfm: false
  use_ema: false
  nll_with_cfm: true
  logz_with_cfm: true
  tol: 1e-3
  use_exact_likelihood: false
  net:
    n_layers: 5
    hidden_nf: 128

  noise_schedule:
    _target_: dem.models.components.noise_schedules.GeometricNoiseSchedule
    sigma_min: 0.01
    sigma_max: 2

  partial_prior:
    _target_: dem.energies.base_prior.MeanFreePrior
    _partial_: true
    n_particles: 13
    spatial_dim: 3

  optimizer:
    lr: 1e-3

  lambda_weighter:
    _target_: dem.models.components.lambda_weighter.NoLambdaWeighter
    _partial_: true

  clipper:
    _target_: dem.models.components.clipper.Clipper
    should_clip_scores: True
    should_clip_log_rewards: False
    max_score_norm: 20
    min_log_reward: null

  diffusion_scale: 0.9 # Dummy for cfm

  num_init_samples: 1 # Dummy for cfm
  num_samples_to_generate_per_epoch: 1 # Dummy for cfm
  num_samples_to_sample_from_buffer: 512 # Batch size for training
  num_samples_to_save: 1000 # Number of samples used to calculate test set ess and logz. Test set nll is calculated on the entire test set
  eval_batch_size: 1000

  init_from_prior: true

  nll_integration_method: dopri5
  cfm_prior_std: 2.



callbacks:
  model_checkpoint:
    monitor: "val/nll"
    save_top_k: -1
